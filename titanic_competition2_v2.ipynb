{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "c8b6865b6276da7a1042bdeb5bcbfeaa12d453d1838a1bac25304c8069a869a3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desabilita warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "# train = pd.read_csv('train.csv')\n",
    "# test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('datasets/titanic/train.csv')\n",
    "test = pd.read_csv('datasets/titanic/test.csv')\n",
    "X = train[list(test.columns)]\n",
    "y = train[train.columns[~train.columns.isin(test.columns)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'S'"
      ]
     },
     "metadata": {},
     "execution_count": 174
    }
   ],
   "source": [
    "X['Embarked'].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def extraiPronome(nome):\n",
    "    return nome.split(',')[1].split('.')[0].strip()\n",
    "\n",
    "# Remome colunas indesejadas no final do tratamento dos dados\n",
    "class AtributosDesejados(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, excluirName=True):\n",
    "        self.excluirName = excluirName\n",
    "    def fit(self, X, y=None):\n",
    "        self.colunasIndesejadas = ['PassengerId', 'Name', 'Ticket', 'Age', 'Fare']\n",
    "        if self.excluirName:\n",
    "            self.colunasIndesejadas.append('Name')\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        if 'Name' not in self.colunasIndesejadas:\n",
    "            X['Name'] = X['Name'].apply(extraiPronome)\n",
    "            \n",
    "            # Trata pronome de tratamento\n",
    "            X['Name'] = X['Name'].replace('Mlle', 'Miss')\n",
    "            X['Name'] = X['Name'].replace(['Ms','Mme', 'Lady', 'the Countess', 'Dona'] , 'Mrs')           \n",
    "            X['Name'] = X['Name'].replace(['the Countess', 'Dona', \n",
    "                                           'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer'], 'Other')\n",
    "\n",
    "\n",
    "        # Define Cabin como a primeira letra\n",
    "        X['Cabin'] = X['Cabin'].str[:1]\n",
    "        ## Preenche com Z os faltantes\n",
    "        X['Cabin'].fillna('Z', inplace=True)\n",
    "        \n",
    "        # Classe para o Sexo para drop 'Sex'\n",
    "        X['Sex_Class'] = 0\n",
    "        X.loc[ X['Sex'] == 'female', 'Sex_Class'] = 0\n",
    "        X.loc[ X['Sex'] == 'male', 'Sex_Class'] = 1\n",
    "        X['Sex_Class'] = X['Sex_Class'].astype(int)\n",
    "\n",
    "\n",
    "        # Classes para as idades para drop 'Age'\n",
    "        ## Preenche com a mediana os faltantes\n",
    "        X['Age_Class'] = ''\n",
    "        X['Age'].fillna(X['Age'].median(), inplace=True)\n",
    "        \n",
    "        X.loc[ X['Age'] < 16, 'Age_Class'] = 'children'\n",
    "        X.loc[(X['Age'] >= 16) & (X['Age'] < 35), 'Age_Class'] = 'young'\n",
    "        X.loc[(X['Age'] > 35) & (X['Age'] < 65), 'Age_Class'] = 'adult'\n",
    "        X.loc[ X['Age'] >= 65, 'Age_Class'] = 'old'\n",
    "\n",
    "\n",
    "        # Classes para tarifa para drop 'Fare'\n",
    "        X['Fare_Class'] = ''\n",
    "        ## Preenche com a mediana os faltantes\n",
    "        X['Fare'].fillna(X['Fare'].median(), inplace=True)\n",
    "\n",
    "        X.loc[ X['Fare'] < 20, 'Fare_Class'] = 'low_fare'\n",
    "        X.loc[(X['Fare'] >= 20) & (X['Fare'] < 60), 'Fare_Class'] = 'median_fare'\n",
    "        X.loc[(X['Fare'] >= 60) & (X['Fare'] < 120), 'Fare_Class'] = 'median_high_fare'\n",
    "        X.loc[ X['Fare'] >= 120, 'Fare_Class'] = 'high_fare'\n",
    "\n",
    "\n",
    "        # Cria característica FamilySize para classificar os tamanhos da família. FamilySize é removido ao final.\n",
    "        X['FamilySize'] = 0\n",
    "        X['FamilySize'] = X['SibSp'] + X['Parch'] + 1\n",
    "        X['FamilySize'] = X['FamilySize'].astype(int)\n",
    "\n",
    "        # X['Single'] = X['FamilySize'].map(lambda x: 1 if x==1 else 0)\n",
    "        # X['Small_family'] = X['FamilySize'].map(lambda x: 1 if 2 <= x <=4 else 0)\n",
    "        # X['Medium_family'] = X['FamilySize'].map(lambda x: 1 if 5 <= x <=7 else 0)\n",
    "        # X['Large_family'] = X['FamilySize'].map(lambda x: 1 if 7 < x else 0)        \n",
    "   \n",
    "\n",
    "        # # Característica se é casada\n",
    "        # X['Is_Married'] = 0\n",
    "        # X['Is_Married'] = X['Name'].map(lambda x: 1 if x=='Mrs' else 0)   \n",
    "   \n",
    "        # Remove colunas indesejadas\n",
    "        X = X.drop(self.colunasIndesejadas,axis=1)\n",
    "        \n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class AtributosNumericos(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.colunasNumericas = X.select_dtypes(include='number').columns\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.colunasNumericas].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class AtributosCategoricos(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.colunasCategoricas = X.select_dtypes(include='object').columns\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.colunasCategoricas].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "trataAtributos = Pipeline([\n",
    "    ('unecaracteristicas', FeatureUnion([\n",
    "        ('pipenum', Pipeline([\n",
    "            ('atributos_numericos', AtributosNumericos()),\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])),\n",
    "        ('pipecat', Pipeline([\n",
    "            ('atributos_categoricos', AtributosCategoricos()),\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]))\n",
    "    ])),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([0.78212291, 0.82022472, 0.84269663, 0.80898876, 0.80337079,\n",
       "        0.79329609, 0.83707865, 0.83146067, 0.79775281, 0.79775281,\n",
       "        0.75977654, 0.8258427 , 0.84269663, 0.78089888, 0.86516854,\n",
       "        0.75977654, 0.79775281, 0.80898876, 0.85393258, 0.85393258,\n",
       "        0.82122905, 0.8258427 , 0.83146067, 0.75842697, 0.8258427 ,\n",
       "        0.82681564, 0.7247191 , 0.88202247, 0.83146067, 0.78651685,\n",
       "        0.77653631, 0.81460674, 0.82022472, 0.84269663, 0.80898876,\n",
       "        0.82681564, 0.82022472, 0.78651685, 0.8258427 , 0.82022472,\n",
       "        0.80446927, 0.81460674, 0.84269663, 0.84269663, 0.76966292,\n",
       "        0.84916201, 0.83146067, 0.80898876, 0.74157303, 0.8258427 ]),\n",
       " 0.8130337078651685,\n",
       " 0.031443151618740436)"
      ]
     },
     "metadata": {},
     "execution_count": 179
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, RepeatedKFold\n",
    "import numpy as np\n",
    "\n",
    "pipetotal = Pipeline([\n",
    "    ('atributosDesejados', AtributosDesejados()),\n",
    "    ('trataAtributos', trataAtributos),\n",
    "    ('classificador', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "parametros = {\n",
    "    'atributosDesejados__excluirName': [False],\n",
    "    'classificador__max_depth': [4],\n",
    "    #'classificador__max_features': [3, 4,'sqrt'],\n",
    "    #'classificador__min_samples_split': [4],\n",
    "    #'classificador__min_samples_leaf': [2],\n",
    "    'classificador__n_estimators' : [50],\n",
    "    'classificador__criterion': ['gini', 'entropy'],\n",
    "    #'classificador__random_state': [0]\n",
    "}\n",
    "\n",
    "modelo = GridSearchCV(pipetotal, param_grid=parametros, n_jobs=-1)\n",
    "\n",
    "scores = cross_validate(modelo, X, y, cv=RepeatedKFold())\n",
    "scores['test_score'], np.mean(scores['test_score']), np.std(scores['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelo.fit(X,y)\n",
    "y_pred = modelo.predict(test)\n",
    "result = test[['PassengerId']]\n",
    "result['Survived'] = y_pred\n",
    "result.to_csv('submission.csv',index=False)"
   ]
  }
 ]
}