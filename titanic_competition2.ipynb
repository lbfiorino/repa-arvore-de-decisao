{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "c8b6865b6276da7a1042bdeb5bcbfeaa12d453d1838a1bac25304c8069a869a3"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Segunda Tarefa do Titanic"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     PassengerId  Pclass                                               Name  \\\n",
       "0              1       3                            Braund, Mr. Owen Harris   \n",
       "1              2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2              3       3                             Heikkinen, Miss. Laina   \n",
       "3              4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4              5       3                           Allen, Mr. William Henry   \n",
       "..           ...     ...                                                ...   \n",
       "886          887       2                              Montvila, Rev. Juozas   \n",
       "887          888       1                       Graham, Miss. Margaret Edith   \n",
       "888          889       3           Johnston, Miss. Catherine Helen \"Carrie\"   \n",
       "889          890       1                              Behr, Mr. Karl Howell   \n",
       "890          891       3                                Dooley, Mr. Patrick   \n",
       "\n",
       "        Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0      male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1    female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2    female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3    female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4      male  35.0      0      0            373450   8.0500   NaN        S  \n",
       "..      ...   ...    ...    ...               ...      ...   ...      ...  \n",
       "886    male  27.0      0      0            211536  13.0000   NaN        S  \n",
       "887  female  19.0      0      0            112053  30.0000   B42        S  \n",
       "888  female   NaN      1      2        W./C. 6607  23.4500   NaN        S  \n",
       "889    male  26.0      0      0            111369  30.0000  C148        C  \n",
       "890    male  32.0      0      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 11 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>2</td>\n      <td>Montvila, Rev. Juozas</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.0000</td>\n      <td>B42</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>3</td>\n      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.4500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.0000</td>\n      <td>C148</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>3</td>\n      <td>Dooley, Mr. Patrick</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows Ã— 11 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#train = pd.read_csv('train.csv')\n",
    "#test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('datasets/titanic/train.csv')\n",
    "test = pd.read_csv('datasets/titanic/test.csv')\n",
    "X = train[list(test.columns)]\n",
    "y = train[train.columns[~train.columns.isin(test.columns)]]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def extraiPronome(nome):\n",
    "    return nome.split(',')[1].split('.')[0].strip()\n",
    "\n",
    "class AtributosDesejados(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, excluirName=True):\n",
    "        self.excluirName = excluirName\n",
    "    def fit(self, X, y=None):\n",
    "        self.colunasIndesejadas = ['PassengerId', 'Ticket', 'Cabin']\n",
    "        if self.excluirName:\n",
    "            self.colunasIndesejadas.append('Name')\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        Xdrop = X.drop(self.colunasIndesejadas,axis=1)\n",
    "        if 'Name' not in self.colunasIndesejadas:\n",
    "            Xdrop['Name'] = Xdrop['Name'].apply(extraiPronome)\n",
    "        return Xdrop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class AtributosNumericos(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.colunasNumericas = X.select_dtypes(include='number').columns\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.colunasNumericas].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class AtributosCategoricos(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.colunasCategoricas = X.select_dtypes(include='object').columns\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.colunasCategoricas].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "trataAtributos = Pipeline([\n",
    "    ('unecaracteristicas', FeatureUnion([\n",
    "        ('pipenum', Pipeline([\n",
    "            ('atributos_numericos', AtributosNumericos()),\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])),\n",
    "        ('pipecat', Pipeline([\n",
    "            ('atributos_categoricos', AtributosCategoricos()),\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ]))\n",
    "    ])),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([0.84375   , 0.8515625 , 0.82677165, 0.80314961, 0.79527559,\n",
       "        0.81889764, 0.87401575, 0.8203125 , 0.8046875 , 0.84251969,\n",
       "        0.8503937 , 0.8503937 , 0.84251969, 0.79527559, 0.84375   ,\n",
       "        0.859375  , 0.86614173, 0.82677165, 0.78740157, 0.78740157,\n",
       "        0.77165354, 0.8515625 , 0.8359375 , 0.82677165, 0.77952756,\n",
       "        0.79527559, 0.81889764, 0.81889764, 0.8046875 , 0.7578125 ,\n",
       "        0.83464567, 0.83464567, 0.82677165, 0.87401575, 0.84251969,\n",
       "        0.8515625 , 0.796875  , 0.81102362, 0.80314961, 0.8503937 ,\n",
       "        0.85826772, 0.82677165, 0.8203125 , 0.8359375 , 0.85826772,\n",
       "        0.82677165, 0.84251969, 0.77952756, 0.81102362, 0.875     ,\n",
       "        0.8359375 , 0.78740157, 0.81102362, 0.81889764, 0.80314961,\n",
       "        0.77165354, 0.8125    , 0.84375   , 0.90551181, 0.77165354,\n",
       "        0.78740157, 0.8976378 , 0.80314961, 0.8125    , 0.7734375 ,\n",
       "        0.88188976, 0.79527559, 0.83464567, 0.84251969, 0.82677165]),\n",
       " 0.8246871484814398,\n",
       " 0.031244065039984868)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, RepeatedKFold\n",
    "import numpy as np\n",
    "\n",
    "pipetotal = Pipeline([\n",
    "    ('atributosDesejados', AtributosDesejados()),\n",
    "    ('trataAtributos', trataAtributos),\n",
    "    ('classificador', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "parametros = {\n",
    "    'atributosDesejados__excluirName': [True, False],\n",
    "    'classificador__max_depth': [5],\n",
    "    #'classificador__criterion': ['gini', 'entropy'],\n",
    "    #'classificador__max_features': ['sqrt', 'log2'],\n",
    "    #'classificador__class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "}\n",
    "modelo = GridSearchCV(pipetotal, param_grid=parametros, n_jobs=-1)\n",
    "\n",
    "scores = cross_validate(modelo, X, y, cv=RepeatedKFold(n_splits=7, n_repeats=10, random_state=None))\n",
    "scores['test_score'], np.mean(scores['test_score']), np.std(scores['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.fit(X,y)\n",
    "y_pred = modelo.predict(test)\n",
    "result = test[['PassengerId']]\n",
    "result['Survived'] = y_pred\n",
    "result.to_csv('submission.csv',index=False)"
   ]
  }
 ]
}